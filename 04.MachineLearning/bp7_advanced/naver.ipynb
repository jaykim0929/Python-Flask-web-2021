{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 네이버 영화 리뷰 분석"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import joblib\n",
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         id                           document  label\n",
       "0   9976970                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                  너무재밓었다그래서보는것을추천한다      0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>document</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9976970</td>\n      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3819312</td>\n      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10265843</td>\n      <td>너무재밓었다그래서보는것을추천한다</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "train_df = pd.read_csv('../../../Machine-Learning/00.data/NaverMovie/ratings_train.txt', sep='\\t')\n",
    "test_df = pd.read_csv('../../../Machine-Learning/00.data/NaverMovie/ratings_test.txt', sep='\\t')\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((150000, 3), (50000, 3))"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "train_df.shape, test_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "146182"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# 중복 여부 확인\n",
    "train_df['document'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(146183, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# 중복 샘플 제거\n",
    "train_df.drop_duplicates(subset=['document'], inplace=True)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "id          0\n",
       "document    1\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Null값 확인\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(146182, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "# Null값 제거\n",
    "train_df = train_df.dropna(how = 'any')\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    73342\n",
       "1    72840\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# 긍정, 부정 레이블 값의 갯수\n",
    "train_df.label.value_counts()"
   ]
  },
  {
   "source": [
    "- 테스트 데이터 셋에도 적용"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(49158, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# 중복 제거\n",
    "test_df.drop_duplicates(subset=['document'], inplace=True)\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(49157, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "# Null 제거\n",
    "test_df = test_df.dropna(how='any')\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        id                                document  label\n",
       "0  6270596                                     굳 ㅋ      1\n",
       "1  9274899                    GDNTOPCLASSINTHECLUB      0\n",
       "2  8544678  뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>document</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6270596</td>\n      <td>굳 ㅋ</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9274899</td>\n      <td>GDNTOPCLASSINTHECLUB</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8544678</td>\n      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "test_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('../static/data/naver/movie_test0.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "source": [
    "### 텍스트 전처리"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         id                    document  label\n",
       "0   9976970           아 더빙 진짜 짜증나네요 목소리      0\n",
       "1   3819312  흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나      1\n",
       "2  10265843           너무재밓었다그래서보는것을추천한다      0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>document</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9976970</td>\n      <td>아 더빙 진짜 짜증나네요 목소리</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3819312</td>\n      <td>흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10265843</td>\n      <td>너무재밓었다그래서보는것을추천한다</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "train_df['document'] = train_df['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "id            0\n",
       "document    391\n",
       "label         0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "train_df['document'].replace('', np.nan, inplace=True)\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(145791, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "train_df = train_df.dropna(how = 'any')\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('../static/data/naver/movie_train.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "source": [
    "- 테스트 데이터셋"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['document'] = test_df['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[True, False, True]"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "indices = list(test_df['document'] != '')\n",
    "indices[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(48995, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "df = pd.read_csv('../static/data/naver/movie_test0.tsv', sep='\\t')\n",
    "new_df = df.loc[indices,:]\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('../static/data/naver/movie_test.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(48995, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "test_df = pd.read_csv('../static/data/naver/movie_test.tsv', sep='\\t')\n",
    "test_df['document'] = test_df['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다','을']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=145791.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7dd844fec09348959ba493aa7192f4ac"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "X_train = []\n",
    "for sentence in tqdm_notebook(train_df['document']):\n",
    "    morphs = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    temp_X = ' '.join([word for word in morphs if not word in stopwords]) # 불용어 제거\n",
    "    X_train.append(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=48995.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c4e6a5d82d064847a1e0f4b476ed5900"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_test = []\n",
    "for sentence in tqdm_notebook(test_df['document']):\n",
    "    morphs = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    temp_X = ' '.join([word for word in morphs if not word in stopwords]) # 불용어 제거\n",
    "    X_test.append(temp_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_df.label.values\n",
    "y_test = test_df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['아 더빙 진짜 짜증나다 목소리',\n",
       " '흠 포스터 보고 초딩 영화 줄 오버 연기 조차 가볍다 않다',\n",
       " '너 무재 밓었 다그 래서 보다 추천 다']"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "X_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 1, 0], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "y_train[:3]"
   ]
  },
  {
   "source": [
    "### Case 1. CountVectorizer + LogisticRegression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('count_vect', CountVectorizer()),\n",
    "    ('lr_clf', LogisticRegression())\n",
    "])\n",
    "params = ({\n",
    "    'count_vect__ngram_range': [(1,1), (1,2)],\n",
    "    'count_vect__max_df': [300, 700],\n",
    "    'lr_clf__C': [1, 10]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 3.3 s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('count_vect', CountVectorizer()),\n",
       "                ('lr_clf', LogisticRegression())])"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "%time pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:  2.3min finished\n",
      "{'count_vect__max_df': 700, 'count_vect__ngram_range': (1, 2), 'lr_clf__C': 1} 0.8180957672284297\n"
     ]
    }
   ],
   "source": [
    "grid_pipe = GridSearchCV(pipeline, param_grid=params, cv=3,\n",
    "                         scoring='accuracy', verbose=1)\n",
    "grid_pipe.fit(X_train, y_train)\n",
    "print(grid_pipe.best_params_, grid_pipe.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8196958873354424"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "best_count_lr = grid_pipe.best_estimator_\n",
    "pred_count_lr = best_count_lr.predict(X_test)\n",
    "accuracy_score(y_test, pred_count_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['../static/model/naver_count_lr.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "joblib.dump(best_count_lr, '../static/model/naver_count_lr.pkl')"
   ]
  },
  {
   "source": [
    "### Case 2. CountVectorizer + NaiveBayes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('count_vect', CountVectorizer()),\n",
    "    ('nb_clf', MultinomialNB())\n",
    "])\n",
    "params = ({\n",
    "    'count_vect__ngram_range': [(1,1), (1,2)],\n",
    "    'count_vect__max_df': [300, 700]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 1.38 s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('count_vect', CountVectorizer()), ('nb_clf', MultinomialNB())])"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "%time pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:   30.5s finished\n",
      "{'count_vect__max_df': 700, 'count_vect__ngram_range': (1, 2)} 0.8266491072837144\n"
     ]
    }
   ],
   "source": [
    "grid_pipe = GridSearchCV(pipeline, param_grid=params, cv=3,\n",
    "                         scoring='accuracy', verbose=1)\n",
    "grid_pipe.fit(X_train, y_train)\n",
    "print(grid_pipe.best_params_, grid_pipe.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8284722930911318"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "best_count_nb = grid_pipe.best_estimator_\n",
    "pred_count_nb = best_count_nb.predict(X_test)\n",
    "accuracy_score(y_test, pred_count_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['../static/model/naver_count_nb.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "joblib.dump(best_count_nb, '../static/model/naver_count_nb.pkl')"
   ]
  },
  {
   "source": [
    "### Case 3. TfidfVectorizer + LogisticRegression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf_vect', TfidfVectorizer()),\n",
    "    ('lr_clf', LogisticRegression())\n",
    "])\n",
    "params = ({\n",
    "    'tfidf_vect__ngram_range': [(1,1), (1,2)],\n",
    "    'tfidf_vect__max_df': [300, 700],\n",
    "    'lr_clf__C': [1, 10]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 3.09 s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf_vect', TfidfVectorizer()),\n",
       "                ('lr_clf', LogisticRegression())])"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "%time pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:  2.1min finished\n",
      "{'lr_clf__C': 10, 'tfidf_vect__max_df': 700, 'tfidf_vect__ngram_range': (1, 2)} 0.8204072953748859\n"
     ]
    }
   ],
   "source": [
    "grid_pipe = GridSearchCV(pipeline, param_grid=params, cv=3,\n",
    "                         scoring='accuracy', verbose=1)\n",
    "grid_pipe.fit(X_train, y_train)\n",
    "print(grid_pipe.best_params_, grid_pipe.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8203490152056332"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "best_tfidf_lr = grid_pipe.best_estimator_\n",
    "pred_tfidf_lr = best_tfidf_lr.predict(X_test)\n",
    "accuracy_score(y_test, pred_tfidf_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['../static/model/naver_tfidf_lr.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "joblib.dump(best_tfidf_lr, '../static/model/naver_tfidf_lr.pkl')"
   ]
  },
  {
   "source": [
    "### Case 4. TfidfVectorizer + NaiveBayes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('tfidf_vect', TfidfVectorizer()),\n",
    "    ('nb_clf', MultinomialNB())\n",
    "])\n",
    "params = ({\n",
    "    'tfidf_vect__ngram_range': [(1,1), (1,2)],\n",
    "    'tfidf_vect__max_df': [300, 700]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 1.36 s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf_vect', TfidfVectorizer()), ('nb_clf', MultinomialNB())])"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "%time pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:   33.0s finished\n",
      "{'tfidf_vect__max_df': 700, 'tfidf_vect__ngram_range': (1, 2)} 0.8286108195979175\n"
     ]
    }
   ],
   "source": [
    "grid_pipe = GridSearchCV(pipeline, param_grid=params, cv=3,\n",
    "                         scoring='accuracy', verbose=1)\n",
    "grid_pipe.fit(X_train, y_train)\n",
    "print(grid_pipe.best_params_, grid_pipe.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8298806000612308"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "best_tfidf_nb = grid_pipe.best_estimator_\n",
    "pred_tfidf_nb = best_tfidf_nb.predict(X_test)\n",
    "accuracy_score(y_test, pred_tfidf_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['../static/model/naver_tfidf_nb.pkl']"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "joblib.dump(best_tfidf_nb, '../static/model/naver_tfidf_nb.pkl')"
   ]
  },
  {
   "source": [
    "### TEST\n",
    " - TEST data set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('이렇게 지겨울수가', 0)"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "index = 100\n",
    "review = test_df.document[index]\n",
    "label = test_df.label[index]\n",
    "review, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['이렇게 지겹다']"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "source": [
    "test_data = []\n",
    "morphs = okt.morphs(review, stem=True) # 토큰화\n",
    "temp_X = ' '.join([word for word in morphs if not word in stopwords]) # 불용어 제거\n",
    "test_data.append(temp_X)\n",
    "test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cl = best_count_lr.predict(test_data)\n",
    "pred_cn = best_count_nb.predict(test_data)\n",
    "pred_tl = best_tfidf_lr.predict(test_data)\n",
    "pred_tn = best_tfidf_nb.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0, 0, 0, 0, 0)"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "label, pred_cl[0], pred_cn[0], pred_tl[0], pred_tn[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "review = '이런 사랑영화가 다시 나올 수 있을까?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['이렇다 사랑 영화 다시 나오다 수 있다']"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "review = re.sub(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\", review)\n",
    "test_data = []\n",
    "morphs = okt.morphs(review, stem=True) # 토큰화\n",
    "temp_X = ' '.join([word for word in morphs if not word in stopwords]) # 불용어 제거\n",
    "test_data.append(temp_X)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cl = best_count_lr.predict(test_data)\n",
    "pred_cn = best_count_nb.predict(test_data)\n",
    "pred_tl = best_tfidf_lr.predict(test_data)\n",
    "pred_tn = best_tfidf_nb.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, 1, 1, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "pred_cl[0], pred_cn[0], pred_tl[0], pred_tn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}